{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Gradient Descent? \n",
    "Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model. Parameters refer to coefficients in Linear Regression and weights in neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets see what is gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ e= (y- \\hat{y})**2$$\n",
    "$$ \\hat{y} = Xb$$\n",
    "$$ e= (y- Xb)**2$$\n",
    "$$ \\frac{de}{db}= 2(y- Xb)(-X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Not its time for us to describe the funcfion of gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent (X, y,tolerance=10**-6,  learning_rate=0.01, max_iter=10000, normalize=False, verbose=0,\n",
    "                      return_errors=False):\n",
    "    if normalize:\n",
    "        X= X/y\n",
    "        y=y/y\n",
    "    iter_ = 0\n",
    "    a= np.random.random()\n",
    "    print(\"a = \", a)\n",
    "    gradient=10\n",
    "    old_gradient=float(\"inf\")  # old_gradient > gradient\n",
    "    errors = []\n",
    "    while (abs(gradient) > tolerance) and (max_iter > iter_):\n",
    "        errors.append((y-X*a)**2)\n",
    "        gradient = 2*(y-X*a)* (-X)\n",
    "        if abs(old_gradient) < abs(gradient):\n",
    "            print(\"Gradient became bigger and bigger\")\n",
    "            print('Gradient difference:', gradient)\n",
    "            break\n",
    "        a = a - learning_rate * gradient\n",
    "        iter_ += 1\n",
    "        old_gradient = gradient\n",
    "        if iter_ % 100 == 0:\n",
    "            print(f'Gradient at iter {iter_}:', gradient)\n",
    "    print(\"Gradient = \",  gradient)\n",
    "    print(\"Iter= \", iter_)\n",
    "    \n",
    "    if return_errors:\n",
    "        return round(a,6), errors\n",
    "    return round(a,6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.10410896524493207\n",
      "Gradient at iter 100: -0.43026820462583204\n",
      "Gradient at iter 200: -0.37968066940798606\n",
      "Gradient at iter 300: -0.3350408168027612\n",
      "Gradient at iter 400: -0.295649365291338\n",
      "Gradient at iter 500: -0.26088924934966495\n",
      "Gradient at iter 600: -0.23021595314152282\n",
      "Gradient at iter 700: -0.20314898069956794\n",
      "Gradient at iter 800: -0.1792643289750796\n",
      "Gradient at iter 900: -0.15818784584703505\n",
      "Gradient at iter 1000: -0.1395893690439885\n",
      "Gradient at iter 1100: -0.12317755416519605\n",
      "Gradient at iter 1200: -0.10869531078214434\n",
      "Gradient at iter 1300: -0.09591577512719607\n",
      "Gradient at iter 1400: -0.084638756281675\n",
      "Gradient at iter 1500: -0.07468760019307363\n",
      "Gradient at iter 1600: -0.06590642239633354\n",
      "Gradient at iter 1700: -0.05815766608988926\n",
      "Gradient at iter 1800: -0.05131994731383305\n",
      "Gradient at iter 1900: -0.04528615347500137\n",
      "Gradient at iter 2000: -0.0399617654324555\n",
      "Gradient at iter 2100: -0.035263376858892304\n",
      "Gradient at iter 2200: -0.03111738768383643\n",
      "Gradient at iter 2300: -0.027458851151460406\n",
      "Gradient at iter 2400: -0.024230456432231484\n",
      "Gradient at iter 2500: -0.021381630851043387\n",
      "Gradient at iter 2600: -0.01886774766826732\n",
      "Gradient at iter 2700: -0.01664942700364863\n",
      "Gradient at iter 2800: -0.014691918952044969\n",
      "Gradient at iter 2900: -0.012964559227543304\n",
      "Gradient at iter 3000: -0.011440288808636678\n",
      "Gradient at iter 3100: -0.010095230059728011\n",
      "Gradient at iter 3200: -0.008908312688915287\n",
      "Gradient at iter 3300: -0.007860943682706623\n",
      "Gradient at iter 3400: -0.006936716047201252\n",
      "Gradient at iter 3500: -0.006121151793181845\n",
      "Gradient at iter 3600: -0.005401475138987699\n",
      "Gradient at iter 3700: -0.004766412378402307\n",
      "Gradient at iter 3800: -0.00420601527849368\n",
      "Gradient at iter 3900: -0.003711505240939994\n",
      "Gradient at iter 4000: -0.0032751357856357632\n",
      "Gradient at iter 4100: -0.0028900712023877673\n",
      "Gradient at iter 4200: -0.0025502794697869757\n",
      "Gradient at iter 4300: -0.0022504377638318807\n",
      "Gradient at iter 4400: -0.0019858490761029968\n",
      "Gradient at iter 4500: -0.0017523686353112522\n",
      "Gradient at iter 4600: -0.0015463389796210314\n",
      "Gradient at iter 4700: -0.001364532662655571\n",
      "Gradient at iter 4800: -0.001204101695677362\n",
      "Gradient at iter 4900: -0.001062532933958471\n",
      "Gradient at iter 5000: -0.0009376087084661533\n",
      "Gradient at iter 5100: -0.0008273720861682876\n",
      "Gradient at iter 5200: -0.0007300962147529511\n",
      "Gradient at iter 5300: -0.0006442572715563699\n",
      "Gradient at iter 5400: -0.0005685105929408296\n",
      "Gradient at iter 5500: -0.0005016696101934892\n",
      "Gradient at iter 5600: -0.0004426872619733291\n",
      "Gradient at iter 5700: -0.00039063959213669897\n",
      "Gradient at iter 5800: -0.0003447112760020521\n",
      "Gradient at iter 5900: -0.0003041828483208997\n",
      "Gradient at iter 6000: -0.00026841943288213876\n",
      "Gradient at iter 6100: -0.00023686079720308673\n",
      "Gradient at iter 6200: -0.000209012576508516\n",
      "Gradient at iter 6300: -0.00018443852952704232\n",
      "Gradient at iter 6400: -0.00016275370478840978\n",
      "Gradient at iter 6500: -0.00014361841037352496\n",
      "Gradient at iter 6600: -0.00012673289265541232\n",
      "Gradient at iter 6700: -0.00011183264066949583\n",
      "Gradient at iter 6800: -9.868424255971009e-05\n",
      "Gradient at iter 6900: -8.708172919164037e-05\n",
      "Gradient at iter 7000: -7.684334765434286e-05\n",
      "Gradient at iter 7100: -6.780871410733136e-05\n",
      "Gradient at iter 7200: -5.98363013748493e-05\n",
      "Gradient at iter 7300: -5.280122192774517e-05\n",
      "Gradient at iter 7400: -4.659327152545245e-05\n",
      "Gradient at iter 7500: -4.111520287242154e-05\n",
      "Gradient at iter 7600: -3.628120224014042e-05\n",
      "Gradient at iter 7700: -3.201554519999261e-05\n",
      "Gradient at iter 7800: -2.8251410404578348e-05\n",
      "Gradient at iter 7900: -2.4929832831754872e-05\n",
      "Gradient at iter 8000: -2.199878010034073e-05\n",
      "Gradient at iter 8100: -1.941233738583792e-05\n",
      "Gradient at iter 8200: -1.7129988166220134e-05\n",
      "Gradient at iter 8300: -1.5115979530688772e-05\n",
      "Gradient at iter 8400: -1.3338762114567526e-05\n",
      "Gradient at iter 8500: -1.177049587730572e-05\n",
      "Gradient at iter 8600: -1.0386613990831517e-05\n",
      "Gradient at iter 8700: -9.165438000113824e-06\n",
      "Gradient at iter 8800: -8.087838231918276e-06\n",
      "Gradient at iter 8900: -7.136934128293415e-06\n",
      "Gradient at iter 9000: -6.297829814372324e-06\n",
      "Gradient at iter 9100: -5.5573807547504295e-06\n",
      "Gradient at iter 9200: -4.903987843918323e-06\n",
      "Gradient at iter 9300: -4.327415708160753e-06\n",
      "Gradient at iter 9400: -3.818632367424968e-06\n",
      "Gradient at iter 9500: -3.369667750829919e-06\n",
      "Gradient at iter 9600: -2.9734888463694986e-06\n",
      "Gradient at iter 9700: -2.6238895264318884e-06\n",
      "Gradient at iter 9800: -2.315393331508986e-06\n",
      "Gradient at iter 9900: -2.043167681597957e-06\n",
      "Gradient at iter 10000: -1.8029481719250562e-06\n",
      "Gradient =  -1.8029481719250562e-06\n",
      "Iter=  10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.999986"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(3,12, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.7583339691477492\n",
      "Gradient at iter 100: -0.11664110053404164\n",
      "Gradient at iter 200: -0.03315599294129107\n",
      "Gradient at iter 300: -0.009424807061059193\n",
      "Gradient at iter 400: -0.0026790628257002957\n",
      "Gradient at iter 500: -0.0007615410668408429\n",
      "Gradient at iter 600: -0.00021647301098037808\n",
      "Gradient at iter 700: -6.15338640598817e-05\n",
      "Gradient at iter 800: -1.74914018563066e-05\n",
      "Gradient at iter 900: -4.9720449638024355e-06\n",
      "Gradient at iter 1000: -1.4133361823098767e-06\n",
      "Gradient =  -9.937666032300285e-07\n",
      "Iter=  1028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.999992"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(3,12, normalize=True, verbose=1, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.4502791806853407\n",
      "Gradient =  -9.173335264733851e-07\n",
      "Iter=  92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(3,12, normalize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.08874019944023559\n",
      "Gradient at iter 100: -0.0008554628509829243\n",
      "Gradient =  -9.977349137990643e-07\n",
      "Iter=  181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(1200,600, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.04017267847081496\n",
      "Gradient at iter 100: -0.018106680037509905\n",
      "Gradient at iter 200: -0.016382781908239524\n",
      "Gradient at iter 300: -0.014823012418451664\n",
      "Gradient at iter 400: -0.013411745232784057\n",
      "Gradient at iter 500: -0.012134841765712744\n",
      "Gradient at iter 600: -0.010979509536084349\n",
      "Gradient at iter 700: -0.009934174007409199\n",
      "Gradient at iter 800: -0.008988362629964965\n",
      "Gradient at iter 900: -0.00813259992300263\n",
      "Gradient at iter 1000: -0.007358312545950332\n",
      "Gradient at iter 1100: -0.006657743407584145\n",
      "Gradient at iter 1200: -0.006023873952680188\n",
      "Gradient at iter 1300: -0.0054503538475878565\n",
      "Gradient at iter 1400: -0.004931437360288487\n",
      "Gradient at iter 1500: -0.004461925797572193\n",
      "Gradient at iter 1600: -0.004037115422647386\n",
      "Gradient at iter 1700: -0.0036527503314030076\n",
      "Gradient at iter 1800: -0.0033049798152204367\n",
      "Gradient at iter 1900: -0.0029903197831807637\n",
      "Gradient at iter 2000: -0.002705617857180711\n",
      "Gradient at iter 2100: -0.002448021790267727\n",
      "Gradient at iter 2200: -0.002214950891797476\n",
      "Gradient at iter 2300: -0.0020040701731408707\n",
      "Gradient at iter 2400: -0.0018132669549226655\n",
      "Gradient at iter 2500: -0.001640629701434826\n",
      "Gradient at iter 2600: -0.0014844288701797458\n",
      "Gradient at iter 2700: -0.0013430995846875082\n",
      "Gradient at iter 2800: -0.0012152259570169322\n",
      "Gradient at iter 2900: -0.001099526902877661\n",
      "Gradient at iter 3000: -0.0009948433072639795\n",
      "Gradient at iter 3100: -0.0009001264120210895\n",
      "Gradient at iter 3200: -0.0008144273090063181\n",
      "Gradient at iter 3300: -0.0007368874335838705\n",
      "Gradient at iter 3400: -0.0006667299632134705\n",
      "Gradient at iter 3500: -0.0006032520349609705\n",
      "Gradient at iter 3600: -0.0005458177039630585\n",
      "Gradient at iter 3700: -0.0004938515723014115\n",
      "Gradient at iter 3800: -0.0004468330244580665\n",
      "Gradient at iter 3900: -0.00040429101160072145\n",
      "Gradient at iter 4000: -0.00036579933244498933\n",
      "Gradient at iter 4100: -0.0003309723634156714\n",
      "Gradient at iter 4200: -0.0002994611953301574\n",
      "Gradient at iter 4300: -0.00027095013790001454\n",
      "Gradient at iter 4400: -0.00024515355703132126\n",
      "Gradient at iter 4500: -0.0002218130132389251\n",
      "Gradient at iter 4600: -0.00020069467250620975\n",
      "Gradient at iter 4700: -0.0001815869636511791\n",
      "Gradient at iter 4800: -0.00016429845872980797\n",
      "Gradient at iter 4900: -0.0001486559552416167\n",
      "Gradient at iter 5000: -0.00013450274092430048\n",
      "Gradient at iter 5100: -0.00012169702375357972\n",
      "Gradient at iter 5200: -0.00011011051141934126\n",
      "Gradient at iter 5300: -9.962712604688617e-05\n",
      "Gradient at iter 5400: -9.014184128674164e-05\n",
      "Gradient at iter 5500: -8.15596301226007e-05\n",
      "Gradient at iter 5600: -7.379451285642658e-05\n",
      "Gradient at iter 5700: -6.676869573257083e-05\n",
      "Gradient at iter 5800: -6.0411791571866046e-05\n",
      "Gradient at iter 5900: -5.4660114607294475e-05\n",
      "Gradient at iter 6000: -4.9456042457014516e-05\n",
      "Gradient at iter 6100: -4.474743884242738e-05\n",
      "Gradient at iter 6200: -4.048713126806547e-05\n",
      "Gradient at iter 6300: -3.6632438430506124e-05\n",
      "Gradient at iter 6400: -3.314474262154476e-05\n",
      "Gradient at iter 6500: -2.998910284206735e-05\n",
      "Gradient at iter 6600: -2.7133904750482608e-05\n",
      "Gradient at iter 6700: -2.455054393875722e-05\n",
      "Gradient at iter 6800: -2.221313936315861e-05\n",
      "Gradient at iter 6900: -2.009827405851983e-05\n",
      "Gradient at iter 7000: -1.8184760538695332e-05\n",
      "Gradient at iter 7100: -1.6453428532545722e-05\n",
      "Gradient at iter 7200: -1.4886932929345509e-05\n",
      "Gradient at iter 7300: -1.3469580009084492e-05\n",
      "Gradient at iter 7400: -1.2187170217154986e-05\n",
      "Gradient at iter 7500: -1.1026855908011779e-05\n",
      "Gradient at iter 7600: -9.977012632915728e-06\n",
      "Gradient at iter 7700: -9.027122681906085e-06\n",
      "Gradient at iter 7800: -8.167669713627923e-06\n",
      "Gradient at iter 7900: -7.390043417101478e-06\n",
      "Gradient at iter 8000: -6.686453250621671e-06\n",
      "Gradient at iter 8100: -6.049850393203826e-06\n",
      "Gradient at iter 8200: -5.473857126980786e-06\n",
      "Gradient at iter 8300: -4.952702942915277e-06\n",
      "Gradient at iter 8400: -4.481166729737307e-06\n",
      "Gradient at iter 8500: -4.054524466985399e-06\n",
      "Gradient at iter 8600: -3.668501898004273e-06\n",
      "Gradient at iter 8700: -3.319231708984738e-06\n",
      "Gradient at iter 8800: -3.0032147847536274e-06\n",
      "Gradient at iter 8900: -2.7172851533463493e-06\n",
      "Gradient at iter 9000: -2.4585782682118307e-06\n",
      "Gradient at iter 9100: -2.224502310155252e-06\n",
      "Gradient at iter 9200: -2.012712221461932e-06\n",
      "Gradient at iter 9300: -1.8210862123901882e-06\n",
      "Gradient at iter 9400: -1.647704504181835e-06\n",
      "Gradient at iter 9500: -1.4908300961513632e-06\n",
      "Gradient at iter 9600: -1.3488913636794386e-06\n",
      "Gradient at iter 9700: -1.2204663131765158e-06\n",
      "Gradient at iter 9800: -1.104268335971881e-06\n",
      "Gradient at iter 9900: -9.991333186931684e-07\n",
      "Gradient =  -9.991333186931684e-07\n",
      "Iter=  9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.995009"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(8,800, learning_rate=5,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets see what happens when gradient > old_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.9208987092755816\n",
      "Gradient became bigger and bigger\n",
      "Gradient difference: 443.3905858643162\n",
      "Gradient =  443.3905858643162\n",
      "Iter=  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.63281"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(3,12, learning_rate=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.8116203599385242\n",
      "Gradient became bigger and bigger\n",
      "Gradient difference: 396655.09341745573\n",
      "Gradient =  396655.09341745573\n",
      "Iter=  1\n",
      "a =  0.6840928544764623\n",
      "Gradient became bigger and bigger\n",
      "Gradient difference: 74486.74615259876\n",
      "Gradient =  74486.74615259876\n",
      "Iter=  1\n",
      "a =  0.097138319861102\n",
      "Gradient =  -7.147928045014851e-07\n",
      "Iter=  19\n",
      "a =  0.1682489290380469\n",
      "Gradient at iter 100: -0.008238499625804252\n",
      "Gradient =  -9.77093804976903e-07\n",
      "Iter=  166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lr in [0.5, 0.1, 0.01, 0.001]:\n",
    "    _, errors = gradient_descent(8, 400, learning_rate=lr, return_errors=True)\n",
    "    plt.plot(errors, label=f'lr={lr}')\n",
    "    \n",
    "plt.legend()\n",
    "plt.ylim(0, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradient descent](http://www.cs.us.es/~fsancho/images/2017-02/gradient_descent.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 Base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
